{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import os\n",
    "from torchvision.transforms import transforms\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import math\n",
    "from torch.utils.data.sampler import RandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = '/home/max/titanic/train.csv'\n",
    "file = pd.read_csv(file_path)\n",
    "file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dummy_data(data, columns):\n",
    "    for column in columns:\n",
    "        data = pd.concat([data, pd.get_dummies(data[column], prefix=column)], axis=1)\n",
    "        data = data.drop(column, axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TitanicDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, root_dir, file_dir, transform = None, train = True):\n",
    "        self.train = train\n",
    "        dummy_columns = ['Pclass', 'Embarked']\n",
    "        self.file = pd.read_csv(os.path.join(root_dir, file_dir))\n",
    "        if not train:\n",
    "            self.indices = self.file['PassengerId'] \n",
    "        list_to_drop = ['PassengerId', 'Name' , 'Ticket', 'Fare', 'Cabin']\n",
    "        self.file.drop(list_to_drop, axis = 'columns', inplace=True)\n",
    "        self.file['Age'] = self.file['Age'].fillna(self.file['Age'].mean())\n",
    "        self.file['Embarked']  = self.file['Embarked'].fillna('S')\n",
    "        self.file = dummy_data(self.file, dummy_columns)\n",
    "        columns = ['Age', 'SibSp', 'Parch']\n",
    "        if train:\n",
    "            self.labels = self.file.loc[:, :'Survived']\n",
    "            self.file.drop(['Survived'], axis = 'columns', inplace = True)\n",
    "        self.file.loc[self.file['Sex'] == 'male', ['Sex']] = 1\n",
    "        self.file.loc[self.file['Sex'] == 'female', ['Sex']] = 0\n",
    "        for column in columns:\n",
    "            self.file[column] = (self.file[column] - self.file[column].mean())/ self.file[column].std()\n",
    "        self.transform = transform\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.file)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        inputs = self.file.iloc[idx].values.astype(np.float32)\n",
    "        inputs = torch.from_numpy(inputs)\n",
    "        if self.train:\n",
    "            labels = self.labels.iloc[idx].values.astype(np.float32)\n",
    "            labels = torch.from_numpy(labels)\n",
    "            return inputs, labels\n",
    "        return self.indices[idx], inputs\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = TitanicDataset('/home/max/titanic/', 'train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "indices = np.array(list(range(len(train_set))))\n",
    "split = 0.33\n",
    "np.random.shuffle(indices)\n",
    "val_idx = indices[:math.floor(len(train_set) * split)]\n",
    "train_idx = indices[math.floor(len(train_set) * split):]\n",
    "train_sampler = RandomSampler(train_idx)\n",
    "val_sampler = RandomSampler(val_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, num_workers=2, batch_size= 32, drop_last=True, sampler=train_sampler)\n",
    "val_loader = DataLoader(train_set, num_workers=2, batch_size = 32, drop_last=True, sampler = val_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_features, output_features, downsample = None):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.downsample = downsample\n",
    "        if downsample:\n",
    "            self.downsample = nn.Linear(input_features, output_features)\n",
    "        self.linear1 = nn.Linear(input_features, output_features)\n",
    "        self.bn1 = nn.BatchNorm1d(output_features)\n",
    "        self.linear2 = nn.Linear(output_features, output_features)\n",
    "        self.bn2 = nn.BatchNorm1d(output_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        \n",
    "        out = F.relu(self.bn1(self.linear1(x)))\n",
    "        out = self.bn2(self.linear2(out))\n",
    "        \n",
    "        if self.downsample:\n",
    "            residual = self.downsample(residual)\n",
    "            \n",
    "        out += residual\n",
    "        out = F.relu(out)\n",
    "        return out        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.block1 = ResBlock(10, 32, downsample=True)\n",
    "        self.block2 = ResBlock(32, 16, downsample=True)\n",
    "        self.block3 = ResBlock(16, 8, downsample=True)\n",
    "        #self.block4 = ResBlock(16, 8, downsample=True)\n",
    "        self.linear = nn.Linear(8, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        out = self.block1(x)\n",
    "        out = self.block2(out)\n",
    "        out = self.block3(out)\n",
    "        #out = self.block4(out)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "net2 = Net()\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net2.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288\n",
      "epoch train accuracy:  0.6736111111111112\n",
      "val accuracy is:  0.7708333333333334\n",
      "epoch train accuracy:  0.8107638888888888\n",
      "val accuracy is:  0.8159722222222222\n",
      "epoch train accuracy:  0.8125\n",
      "val accuracy is:  0.8263888888888888\n",
      "epoch train accuracy:  0.8055555555555556\n",
      "val accuracy is:  0.8263888888888888\n",
      "epoch train accuracy:  0.8142361111111112\n",
      "val accuracy is:  0.8229166666666666\n",
      "epoch train accuracy:  0.8072916666666666\n",
      "val accuracy is:  0.8298611111111112\n",
      "epoch train accuracy:  0.8211805555555556\n",
      "val accuracy is:  0.8333333333333334\n",
      "epoch train accuracy:  0.8368055555555556\n",
      "val accuracy is:  0.8229166666666666\n",
      "epoch train accuracy:  0.8211805555555556\n",
      "val accuracy is:  0.8229166666666666\n",
      "epoch train accuracy:  0.8298611111111112\n",
      "val accuracy is:  0.8263888888888888\n",
      "epoch train accuracy:  0.828125\n",
      "val accuracy is:  0.8368055555555556\n",
      "epoch train accuracy:  0.8177083333333334\n",
      "val accuracy is:  0.8229166666666666\n",
      "epoch train accuracy:  0.8368055555555556\n",
      "val accuracy is:  0.8368055555555556\n",
      "epoch train accuracy:  0.8402777777777778\n",
      "val accuracy is:  0.8402777777777778\n",
      "epoch train accuracy:  0.828125\n",
      "val accuracy is:  0.8333333333333334\n",
      "epoch train accuracy:  0.8420138888888888\n",
      "val accuracy is:  0.8368055555555556\n",
      "epoch train accuracy:  0.8315972222222222\n",
      "val accuracy is:  0.84375\n",
      "epoch train accuracy:  0.8489583333333334\n",
      "val accuracy is:  0.84375\n",
      "epoch train accuracy:  0.8368055555555556\n",
      "val accuracy is:  0.8229166666666666\n",
      "epoch train accuracy:  0.8368055555555556\n",
      "val accuracy is:  0.8298611111111112\n",
      "epoch train accuracy:  0.8229166666666666\n",
      "val accuracy is:  0.8402777777777778\n",
      "epoch train accuracy:  0.8454861111111112\n",
      "val accuracy is:  0.8298611111111112\n",
      "epoch train accuracy:  0.8368055555555556\n",
      "val accuracy is:  0.8333333333333334\n",
      "epoch train accuracy:  0.8246527777777778\n",
      "val accuracy is:  0.8368055555555556\n",
      "epoch train accuracy:  0.8454861111111112\n",
      "val accuracy is:  0.8506944444444444\n",
      "epoch train accuracy:  0.8420138888888888\n",
      "val accuracy is:  0.8298611111111112\n",
      "epoch train accuracy:  0.8402777777777778\n",
      "val accuracy is:  0.8472222222222222\n",
      "epoch train accuracy:  0.8263888888888888\n",
      "val accuracy is:  0.8298611111111112\n",
      "epoch train accuracy:  0.8489583333333334\n",
      "val accuracy is:  0.8333333333333334\n",
      "epoch train accuracy:  0.828125\n",
      "val accuracy is:  0.8541666666666666\n",
      "epoch train accuracy:  0.8402777777777778\n",
      "val accuracy is:  0.8229166666666666\n",
      "epoch train accuracy:  0.8402777777777778\n",
      "val accuracy is:  0.84375\n",
      "epoch train accuracy:  0.8611111111111112\n",
      "val accuracy is:  0.84375\n",
      "epoch train accuracy:  0.8576388888888888\n",
      "val accuracy is:  0.84375\n",
      "epoch train accuracy:  0.8472222222222222\n",
      "val accuracy is:  0.84375\n",
      "epoch train accuracy:  0.8697916666666666\n",
      "val accuracy is:  0.8333333333333334\n",
      "epoch train accuracy:  0.8524305555555556\n",
      "val accuracy is:  0.8506944444444444\n",
      "epoch train accuracy:  0.8559027777777778\n",
      "val accuracy is:  0.8402777777777778\n",
      "epoch train accuracy:  0.8385416666666666\n",
      "val accuracy is:  0.8506944444444444\n",
      "epoch train accuracy:  0.8368055555555556\n",
      "val accuracy is:  0.8402777777777778\n",
      "epoch train accuracy:  0.8524305555555556\n",
      "val accuracy is:  0.84375\n",
      "epoch train accuracy:  0.84375\n",
      "val accuracy is:  0.8402777777777778\n",
      "epoch train accuracy:  0.8368055555555556\n",
      "val accuracy is:  0.8402777777777778\n",
      "epoch train accuracy:  0.8576388888888888\n",
      "val accuracy is:  0.8611111111111112\n",
      "epoch train accuracy:  0.8402777777777778\n",
      "val accuracy is:  0.8194444444444444\n",
      "epoch train accuracy:  0.8559027777777778\n",
      "val accuracy is:  0.84375\n",
      "epoch train accuracy:  0.8541666666666666\n",
      "val accuracy is:  0.8576388888888888\n",
      "epoch train accuracy:  0.8628472222222222\n",
      "val accuracy is:  0.8576388888888888\n",
      "epoch train accuracy:  0.8454861111111112\n",
      "val accuracy is:  0.8472222222222222\n",
      "epoch train accuracy:  0.8559027777777778\n",
      "val accuracy is:  0.8402777777777778\n",
      "epoch train accuracy:  0.8559027777777778\n",
      "val accuracy is:  0.8506944444444444\n",
      "epoch train accuracy:  0.8645833333333334\n",
      "val accuracy is:  0.8472222222222222\n",
      "epoch train accuracy:  0.8489583333333334\n",
      "val accuracy is:  0.8541666666666666\n",
      "epoch train accuracy:  0.859375\n",
      "val accuracy is:  0.8645833333333334\n",
      "epoch train accuracy:  0.8541666666666666\n",
      "val accuracy is:  0.8611111111111112\n",
      "epoch train accuracy:  0.859375\n",
      "val accuracy is:  0.8576388888888888\n",
      "epoch train accuracy:  0.8576388888888888\n",
      "val accuracy is:  0.8506944444444444\n",
      "epoch train accuracy:  0.8680555555555556\n",
      "val accuracy is:  0.8368055555555556\n",
      "epoch train accuracy:  0.8611111111111112\n",
      "val accuracy is:  0.8472222222222222\n",
      "epoch train accuracy:  0.8663194444444444\n",
      "val accuracy is:  0.84375\n",
      "epoch train accuracy:  0.8628472222222222\n",
      "val accuracy is:  0.8541666666666666\n",
      "epoch train accuracy:  0.875\n",
      "val accuracy is:  0.8541666666666666\n",
      "epoch train accuracy:  0.8628472222222222\n",
      "val accuracy is:  0.84375\n",
      "epoch train accuracy:  0.8506944444444444\n",
      "val accuracy is:  0.8368055555555556\n",
      "epoch train accuracy:  0.8680555555555556\n",
      "val accuracy is:  0.8576388888888888\n",
      "epoch train accuracy:  0.8628472222222222\n",
      "val accuracy is:  0.8506944444444444\n",
      "epoch train accuracy:  0.8663194444444444\n",
      "val accuracy is:  0.8576388888888888\n",
      "epoch train accuracy:  0.8628472222222222\n",
      "val accuracy is:  0.8576388888888888\n",
      "epoch train accuracy:  0.8611111111111112\n",
      "val accuracy is:  0.8506944444444444\n",
      "epoch train accuracy:  0.8732638888888888\n",
      "val accuracy is:  0.8680555555555556\n",
      "epoch train accuracy:  0.8628472222222222\n",
      "val accuracy is:  0.8472222222222222\n",
      "epoch train accuracy:  0.8524305555555556\n",
      "val accuracy is:  0.8541666666666666\n",
      "epoch train accuracy:  0.8576388888888888\n",
      "val accuracy is:  0.8645833333333334\n",
      "epoch train accuracy:  0.8454861111111112\n",
      "val accuracy is:  0.8506944444444444\n",
      "epoch train accuracy:  0.8645833333333334\n",
      "val accuracy is:  0.8645833333333334\n",
      "epoch train accuracy:  0.8697916666666666\n",
      "val accuracy is:  0.8611111111111112\n",
      "epoch train accuracy:  0.8697916666666666\n",
      "val accuracy is:  0.84375\n",
      "epoch train accuracy:  0.8715277777777778\n",
      "val accuracy is:  0.8506944444444444\n",
      "epoch train accuracy:  0.859375\n",
      "val accuracy is:  0.8576388888888888\n",
      "epoch train accuracy:  0.8697916666666666\n",
      "val accuracy is:  0.8576388888888888\n",
      "epoch train accuracy:  0.8697916666666666\n",
      "val accuracy is:  0.8576388888888888\n",
      "epoch train accuracy:  0.8802083333333334\n",
      "val accuracy is:  0.8541666666666666\n",
      "epoch train accuracy:  0.8715277777777778\n",
      "val accuracy is:  0.8611111111111112\n",
      "epoch train accuracy:  0.8802083333333334\n",
      "val accuracy is:  0.8541666666666666\n",
      "epoch train accuracy:  0.8663194444444444\n",
      "val accuracy is:  0.8506944444444444\n",
      "epoch train accuracy:  0.8663194444444444\n",
      "val accuracy is:  0.8680555555555556\n",
      "epoch train accuracy:  0.8767361111111112\n",
      "val accuracy is:  0.8541666666666666\n",
      "epoch train accuracy:  0.8628472222222222\n",
      "val accuracy is:  0.8541666666666666\n",
      "epoch train accuracy:  0.8680555555555556\n",
      "val accuracy is:  0.8645833333333334\n",
      "epoch train accuracy:  0.8802083333333334\n",
      "val accuracy is:  0.8541666666666666\n",
      "epoch train accuracy:  0.8663194444444444\n",
      "val accuracy is:  0.8472222222222222\n",
      "epoch train accuracy:  0.8645833333333334\n",
      "val accuracy is:  0.8472222222222222\n",
      "epoch train accuracy:  0.8802083333333334\n",
      "val accuracy is:  0.8611111111111112\n",
      "epoch train accuracy:  0.875\n",
      "val accuracy is:  0.8541666666666666\n",
      "epoch train accuracy:  0.8680555555555556\n",
      "val accuracy is:  0.8645833333333334\n",
      "epoch train accuracy:  0.8732638888888888\n",
      "val accuracy is:  0.8576388888888888\n",
      "epoch train accuracy:  0.875\n",
      "val accuracy is:  0.8506944444444444\n",
      "epoch train accuracy:  0.8715277777777778\n",
      "val accuracy is:  0.8715277777777778\n",
      "epoch train accuracy:  0.8576388888888888\n",
      "val accuracy is:  0.8576388888888888\n",
      "epoch train accuracy:  0.8663194444444444\n",
      "val accuracy is:  0.8541666666666666\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "best_acc = 0\n",
    "print(len(val_loader) * val_loader.batch_size)\n",
    "for i in range(epochs):\n",
    "    curr_loss = 0\n",
    "    sum_ = 0\n",
    "    net2.train()\n",
    "    for idx, data in enumerate(train_loader):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        inputs, labels = data\n",
    "        inputs = Variable(inputs.float())\n",
    "        labels = Variable(labels.long())\n",
    "        outputs = net2(inputs)\n",
    "        labels = labels.squeeze()\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        curr_loss += loss.data[0]\n",
    "        _, ans = torch.max(outputs, 1)\n",
    "        correct = [labels[i].float() == ans[i].float() for i in range(len(labels))]\n",
    "        sum_ += sum(correct).data[0]\n",
    "        if idx % 20 == 19:\n",
    "            #print('curr. loss: ', curr_loss / 20)\n",
    "            curr_loss = 0\n",
    "    print('epoch train accuracy: ', sum_ / (len(train_loader) * train_loader.batch_size))\n",
    "    \n",
    "    sum_ = 0\n",
    "    net2.eval()\n",
    "    for idx, data in enumerate(val_loader):\n",
    "        \n",
    "        inputs, labels = data\n",
    "        inputs = Variable(inputs.float())\n",
    "        labels = Variable(labels.long())\n",
    "        \n",
    "        outputs = net2(inputs)\n",
    "        _, ans = torch.max(outputs, 1)\n",
    "        \n",
    "        correct = [labels[i].float() == ans[i].float() for i in range(len(labels))]\n",
    "        sum_ += sum(correct).data[0]\n",
    "    print('val accuracy is: ', sum_ / (len(val_loader) * val_loader.batch_size))\n",
    "    if sum_ / (len(val_loader) * val_loader.batch_size) > best_acc:\n",
    "        best_acc = sum_ / (len(val_loader) * val_loader.batch_size)\n",
    "        torch.save(net2.state_dict(), '/home/max/titanic_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8715277777777778\n"
     ]
    }
   ],
   "source": [
    "print(best_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "net2.load_state_dict(torch.load('/home/max/titanic_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = TitanicDataset('/home/max/titanic/', 'test.csv', train = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_data, batch_size = 1, num_workers= 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "net2.eval()\n",
    "csv_data = [['PassengerId', 'Survived']]\n",
    "for idx,data in enumerate(test_loader):\n",
    "    num, inputs = data\n",
    "    #print(num, inputs)\n",
    "    inputs = Variable(inputs.float())\n",
    "    outputs = net2(inputs)\n",
    "    _, ans = torch.max(outputs, 1)\n",
    "    #print(ans)\n",
    "    csv_data.append([str(num[0]), str(ans.data[0])])\n",
    "#print(csv_data)\n",
    "with open(\"/home/max/titanic.csv\", 'w') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerows(csv_data)\n",
    "csvfile.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId  Survived\n",
      "0            892         0\n",
      "1            893         0\n",
      "2            894         0\n",
      "3            895         0\n",
      "4            896         0\n",
      "5            897         0\n",
      "6            898         1\n",
      "7            899         0\n",
      "8            900         0\n",
      "9            901         0\n",
      "10           902         0\n",
      "11           903         0\n",
      "12           904         1\n",
      "13           905         0\n",
      "14           906         1\n",
      "15           907         1\n",
      "16           908         0\n",
      "17           909         0\n",
      "18           910         1\n",
      "19           911         1\n",
      "20           912         0\n",
      "21           913         1\n",
      "22           914         1\n",
      "23           915         0\n",
      "24           916         1\n",
      "25           917         0\n",
      "26           918         1\n",
      "27           919         0\n",
      "28           920         0\n",
      "29           921         0\n",
      "..           ...       ...\n",
      "388         1280         0\n",
      "389         1281         0\n",
      "390         1282         0\n",
      "391         1283         1\n",
      "392         1284         1\n",
      "393         1285         0\n",
      "394         1286         0\n",
      "395         1287         1\n",
      "396         1288         0\n",
      "397         1289         1\n",
      "398         1290         0\n",
      "399         1291         0\n",
      "400         1292         1\n",
      "401         1293         0\n",
      "402         1294         1\n",
      "403         1295         0\n",
      "404         1296         1\n",
      "405         1297         0\n",
      "406         1298         0\n",
      "407         1299         1\n",
      "408         1300         1\n",
      "409         1301         1\n",
      "410         1302         1\n",
      "411         1303         1\n",
      "412         1304         0\n",
      "413         1305         0\n",
      "414         1306         1\n",
      "415         1307         0\n",
      "416         1308         0\n",
      "417         1309         1\n",
      "\n",
      "[418 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(pd.read_csv('/home/max/titanic.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
